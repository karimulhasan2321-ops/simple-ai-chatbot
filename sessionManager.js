const { Client, LocalAuth } = require('whatsapp-web.js');
const qrcode = require('qrcode');
const OpenAI = require('openai');
const db = require('./database');
const fetch = (...args) => import('node-fetch').then(({ default: fetch }) => fetch(...args));

class SessionManager {
    constructor(io) {
        this.io = io;
        this.client = null;
        this.qrCode = null;
        this.status = 'Offline';
        this.chatHistory = []; // temporary in-memory history for UI
        this.userContext = {}; // { phoneNumber: [ { role: 'user'|'assistant', content: '...' } ] }
    }

    async startSession() {
        if (this.client) return;

        console.log(`Starting WhatsApp Client...`);
        this.updateStatus('Initializing...');

        this.client = new Client({
            authStrategy: new LocalAuth({ clientId: 'whatsapp-bot' }),
            puppeteer: {
                headless: true,
                args: ['--no-sandbox', '--disable-setuid-sandbox']
            }
        });

        this.client.on('qr', (qr) => {
            console.log(`QR Code received`);
            this.qrCode = qr;
            this.updateStatus('QR Code Ready');
            this.io.emit('qr', { qr });
        });

        this.client.on('ready', () => {
            console.log(`WhatsApp Client is ready!`);
            this.qrCode = null;
            this.updateStatus('Ready');
            this.io.emit('ready');
        });

        this.client.on('authenticated', () => {
            this.updateStatus('Authenticated');
        });

        this.client.on('auth_failure', () => {
            this.updateStatus('Auth Failure');
            this.qrCode = null;
        });

        this.client.on('disconnected', (reason) => {
            console.log(`Client disconnected:`, reason);
            this.updateStatus('Disconnected');
            this.destroySession();
        });

        this.client.on('message', async (msg) => {
            // Log incoming to UI history
            const incomingLog = {
                from: msg.from,
                body: msg.body,
                type: 'incoming',
                timestamp: new Date()
            };
            this.chatHistory.push(incomingLog);
            if (this.chatHistory.length > 50) this.chatHistory.shift();
            this.io.emit('message', incomingLog);

            console.log(`[Message] ${msg.from}: ${msg.body}`);

            // Ignore status updates
            if (msg.from === 'status@broadcast' || msg.isStatus) return;

            // Update User Context (Memory)
            if (!this.userContext[msg.from]) {
                this.userContext[msg.from] = [];
            }
            this.userContext[msg.from].push({ role: 'user', content: msg.body });
            // Keep last 20 messages for context
            if (this.userContext[msg.from].length > 20) {
                this.userContext[msg.from] = this.userContext[msg.from].slice(-20);
            }

            // Auto-reply logic
            try {
                const settings = this.getSettings();
                if (!settings.openai_key) {
                    this.pushSystemMessage('No OpenAI API Key set. Auto-reply skipped.');
                    return;
                }

                this.pushSystemMessage(`Generating reply for ${msg.from}...`);

                // Process with LLM using History
                const reply = await this.generateReply(msg.from, settings);

                if (reply) {
                    await msg.reply(reply);

                    // Add reply to memory
                    this.userContext[msg.from].push({ role: 'assistant', content: reply });
                    // Keep last 20 messages for context
                    if (this.userContext[msg.from].length > 20) {
                        this.userContext[msg.from] = this.userContext[msg.from].slice(-20);
                    }

                    const outgoingLog = {
                        from: 'Bot',
                        to: msg.from,
                        body: reply,
                        type: 'outgoing',
                        timestamp: new Date()
                    };
                    this.chatHistory.push(outgoingLog);
                    if (this.chatHistory.length > 50) this.chatHistory.shift();
                    this.io.emit('message', outgoingLog);

                    console.log(`[Replied] ${reply}`);
                } else {
                    this.pushSystemMessage('No reply generated by LLM.');
                }
            } catch (error) {
                console.error(`Error in auto-reply:`, error);
                this.io.emit('message', { type: 'system', body: `Error: ${error.message}` });
            }
        });

        this.client.on('message_create', (msg) => {
            if (msg.fromMe) {
                // Capture own messages sent via phone
                const outgoingLog = {
                    from: 'Me',
                    body: msg.body,
                    type: 'outgoing',
                    timestamp: new Date()
                };
                this.chatHistory.push(outgoingLog);
                if (this.chatHistory.length > 50) this.chatHistory.shift();
                this.io.emit('message', outgoingLog);

                // Add to context (optional, but good for flow)
                // We need to know who it was sent TO, which is msg.to
                if (!this.userContext[msg.to]) {
                    this.userContext[msg.to] = [];
                }
                this.userContext[msg.to].push({ role: 'assistant', content: msg.body });
                if (this.userContext[msg.to].length > 20) { // Limit context
                    this.userContext[msg.to] = this.userContext[msg.to].slice(-20);
                }
            }
        });

        try {
            await this.client.initialize();
        } catch (e) {
            console.error(`Failed to initialize client:`, e);
            this.updateStatus('Failed');
        }
    }

    async destroySession() {
        if (this.client) {
            try {
                await this.client.destroy();
            } catch (e) {
                console.error(`Error destroying client:`, e);
            }
            this.client = null;
            this.qrCode = null;
            this.updateStatus('Offline');
        }
    }

    updateStatus(status) {
        this.status = status;
        this.io.emit('status', { status });
    }

    pushSystemMessage(text) {
        this.io.emit('message', { type: 'system', body: text });
    }

    getSettings() {
        const rows = db.prepare('SELECT key, value FROM settings').all();
        const settings = {};
        rows.forEach(row => settings[row.key] = row.value);
        return settings;
    }

    async generateReply(userId, settings) {
        try {
            const openai = new OpenAI({
                apiKey: settings.openai_key,
                baseURL: settings.openai_url // Support for other providers
            });

            // Construct messages array from history
            const history = this.userContext[userId] || [];

            const messages = [
                { role: "system", content: settings.system_prompt },
                ...history
            ];

            const completion = await openai.chat.completions.create({
                messages: messages,
                model: settings.openai_model || "gpt-3.5-turbo",
            });

            return completion.choices[0].message.content;
        } catch (error) {
            console.error("LLM Error:", error);
            // Log the full error object to help debug
            if (error.response) {
                console.error("LLM Response Data:", error.response.data);
                console.error("LLM Response Status:", error.response.status);
            }
            this.pushSystemMessage(`LLM Error: ${error.message}`);
            return null;
        }
    }

    async getGroqModels(apiKey) {
        try {
            const response = await fetch('https://api.groq.com/openai/v1/models', {
                headers: {
                    'Authorization': `Bearer ${apiKey}`,
                    'Content-Type': 'application/json'
                }
            });
            const data = await response.json();
            return data.data || [];
        } catch (e) {
            console.error("Error fetching models:", e);
            return [];
        }
    }
}

module.exports = SessionManager;
